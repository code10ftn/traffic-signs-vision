#command = TrainConvNet:Eval
command = Eval

makeMode = false ; traceLevel = 0 ; deviceId = "auto"

rootDir = "." ; dataDir  = "$rootDir$/gtsrb" ; modelDir = "$rootDir$/models"

modelPath = "$modelDir$/gtsrb.cmf"

# Training action
TrainConvNet = {
    action = "train"

    BrainScriptNetworkBuilder = {
        imageShape = 32:32:3
        labelDim = 43

        model (features) = {
            MyLayer (x, depth, initValueScale) =
            {
                c = ConvolutionalLayer {depth, (5:5), pad = true,
                                        init = "gaussian", initValueScale = initValueScale} (x)
                b = BatchNormalizationLayer {spatialRank = 2, normalizationTimeConstant = 4096} (c)
                r = ReLU (b)
                p = MaxPoolingLayer {(3:3), stride = (2:2)} (r)
            }.p
            featNorm = features - Constant (128)
            p1 = MyLayer (featNorm, 32, 0.0043)
            p2 = MyLayer (p1,       32, 1.414)
            p3 = MyLayer (p2,       64, 1.414)
            d1 = DenseLayer {64, init = "gaussian", initValueScale = 12} (p3)
            d1_bnr = ReLU (BatchNormalizationLayer {normalizationTimeConstant = 4096} (d1))
            d1_d = Dropout (d1_bnr)
            z  = LinearLayer {labelDim, init = "gaussian", initValueScale = 1.5} (d1_d)
        }.z

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
        ce       = CrossEntropyWithSoftmax (labels, z)
        errs     = ErrorPrediction         (labels, z)

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (z)
    }

    SGD = {
        epochSize = 39209

        maxEpochs = 240 ; minibatchSize = 64
        learningRatesPerSample = 0.00046875*7:0.00015625*10:0.000046875*10:0.000015625
        momentumAsTimeConstant = 0
        L2RegWeight = 0
        dropoutRate = 0*1:0.5

        firstMBsToShowResult = 10 ; numMBsToShowResult = 100
    }

    reader = {
        verbosity = 0 ; randomize = true
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "$dataDir$/train_map.txt"
            input = {
                features = { transforms = (
                    #{ type = "Crop" ; cropType = "random" ; cropRatio = 0.8 ; jitterType = "uniRatio" } :
                    { type = "Scale" ; width = 32 ; height = 32 ; channels = 3 ; interpolations = "linear" }
                    #: { type = "Transpose" }
                )}
                labels = { labelDim = 43 }
            }
        })
    }
}

# Eval action
Eval = {
    action = "eval"
    minibatchSize = 16
    evalNodeNames = errs
    reader = {
        verbosity = 0 ; randomize = true
        deserializers = ({
            type = "ImageDeserializer" ; module = "ImageReader"
            file = "$dataDir$/test_map.txt"
            input = {
                features = { transforms = (
                   { type = "Scale" ; width = 32 ; height = 32 ; channels = 3 ; interpolations = "linear" }
                   #: { type = "Transpose" }
                )}
                labels = { labelDim = 43 }
            }
        })
    }
}
